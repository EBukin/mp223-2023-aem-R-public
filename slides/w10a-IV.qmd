---
title: "Instrumental Variable"
editor: source
format:
  revealjs: 
    incremental: true
    smaller: false
    scrollable: false
    code-overflow: wrap
    code-copy: true
    header-includes: |
      <link href="custom.css" rel="stylesheet">
bibliography: ../bib/references.bib
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  fig.width = 7,
  fig.asp = 0.618,
  fig.retina = 3,
  out.width = "100%"
)

library(tidyverse)
library(modelsummary)
library(palmerpenguins)
library(ggpubr)
library(wooldridge)
library(here)
library(parameters)
library(performance)
library(lmtest)
```

# Return to schooling and the Selection bias

-   **Does more years of schooling cause higher wages?**

-   **What other methods can we use to compute the return to schooling?**

## Short Regression

$$
Y_i = \alpha^S + \rho^S s_i + \beta^S X_i + \varepsilon_i^S
$$ {#eq-mincer-short}

-   annual earning $Y_i$
-   years of education $s_i$
-   $X_i$ vector of other control variables, such as experience.

. . .

Is the ceteris paribus fulfilled in @eq-mincer-short?

-   Is control for experience and education sufficient?

-   At a given experience/education level, are more- and less-educated workers equally able and diligent? [see @Angrist2014, Ch. 6]

## Long Regression

$$
Y_i = \alpha + \rho s_i + \beta X_i + \gamma A^{'}_{i} + \varepsilon_i
$$ {#eq-long}

-   where $A^{'}_{i}$ is the ability variable that we desire to have in order to ensure the unbiased estimates of $\rho$.

-   Omitting $A^{'}_{i}$ causes a selection bias or endogeneity:

    -   $\rho^{S} = \rho + \underbrace{\delta_{A^{'} s} \times \gamma}_{\text{ability bias}}$

# Endogeneity

**Is another terminology for a selection bias!**

## Definition

-   Consider following **LONG** and **SHORT** models:

. . .

$$
\begin{aligned}
Y_i &= \alpha + \rho s_i + \beta X_i + \gamma A^{'}_{i} + \varepsilon_i , && \text{long}\\
Y_i &= \alpha^S + \rho^S s_i + \beta^S X_i + \varepsilon_i^S , && \text{short}
\end{aligned}
$$

-   $s_i$ is the causal variable of interest (education)

-   $A^{'}_{i}$ is the vector of control variables that we desire to have in order to ensure unbiased estimates of $\rho$;

-   Variable $s_i$ is **endogenous** if it correlates with the error terms $\varepsilon^{S}_i$ :

. . .

$$ 
Cov(s_i, \varepsilon^{S}_i) \neq 0
$$

## Endogeneity in practice:

::: columns
::: {.column width="75%"}
-   variation in the independent variable $s_i$ (education) is not "random" as compared to the variation in the dependent variable $Y_i$, but

-   an external process $U$ affects variation in both $s_i$ and $Y_i$;

-   thus, $s_i$ is endogenous to $Y_i$;

::: fragment
![](img/w10/ovb-scheme-1.png)
:::
:::

::: {.column width="25%"}
::: fragment
If variance of $s_i$ is truly independent of $Y_i$, $s_i$ is exogenous.
:::
:::
:::

## Causes of endogeneity

-   Omitted Variable Bias (familiar)

-   Measurement Error

-   Simultaneity

## OVB

![](img/w10/ovb-scheme-1.png)

## Measurement error

![](img/w10/meserr-scheme-1.png)

## Measurement error

-   We estimate a long model: $Y_i = \alpha + \beta s^*_i + e_i$ ,

    -   but $s^*_i$ is unavailable, we only have $s_i = s^*_i + m_i$ instead,
    -   $m_i$ is a systematic measurement error,
    -   $E[m_i] =0$ and $Cov(s^*_i, m_i) = Cov(e_i, m_i) = 0$.

-   Desired coefficient $\beta = \frac{Cov(Y_i, s_i)}{Var(s_i)}$

-   But with the erroneous data, we estimate biased coefficient $\beta_b$

. . .

$$
\begin{aligned}
\beta_b & =  
\frac{Cov(Y_i, s_i)}{Var(s_i)}  = 
\frac{Cov(a+\beta s^*_i + e_i, s^*_i + m_i)}{Var(s_i)} \\  
& =  \frac{\beta \cdot Cov(s^*_i, s^*_i)}{Var(s_i)}  =  \beta \frac{Var(s^{*}_i)}{Var(s_i)} 
\end{aligned}
$$

-   [see @Angrist2014, Ch. 6]

## Simultaneity

![](img/w10/simultaneity-scheme-1.png)

## Simultaneity

-   Simultaneity occurs if at least two variables are jointly determined.

    -   A typical case is when observed outcomes are the result of separate behavioral mechanisms that are coordinated in an equilibrium.

-   The prototypical case is a system of demand and supply equations:

    -   $D(p)$ = how high would demand be if the price was set to $p$?
    -   $S(p)$ = how high would supply be if the price was set to $p$?

-   Number of police people and the crime rate.

-   [see @wooldridge2020introductory, Ch. 17] for more details on the problem and solutions.

# IV - one of the solutions to endogeneity

IV stands for Instrumental Variable

## Instrumental Variable

is another variable $Z_i$ that affects only endogenous regressor $s_i$ and satisfies:

::: columns
::: {.column width="60%"}
::: fragment
![](img/w10/iv-scheme-1.png)
:::
:::

::: {.column width="40%"}
::: fragment
1.  **Relevance condition:**

2.  **Exclusion restriction:**

3.  **Independence assumption:**
:::
:::
:::

[see @Angrist2014 Ch. 3 and 6; @Angrist2009, Ch. 4.; @Hernan2020, Ch. 16; @Wooldridge2010, Ch. 8; @Soederbom2014, Ch. 11; @Imbens2020]

## 1. Relevance condition:

::: columns
::: {.column width="40%"}
-   $Z_i$ has a causal effect on $s_i$;
:::

::: {.column width="60%"}
::: fragment
**Violation of the relevance condition:** ![](img/w10/iv-relevance-violation.png)
:::
:::
:::

## 2. Exclusion restriction:

::: columns
::: {.column width="40%"}
-   $Z_i$ does not affect $Y_i$ directly, except through its potential effect on $s_i$;
:::

::: {.column width="60%"}
::: fragment
**Violation of the exclusion restriction:** ![](img/w10/iv-exclusion-violation.png)
:::
:::
:::

## 3. Independence assumption:

::: columns
::: {.column width="40%"}
-   $Z_i$ is randomly assigned or "as good as randomly assigned", the same as
-   $Z_i$ is unrelated to the omitted variables $A^{'}_i$, same as
-   $Z_i$ and $Y_i$ do not share any common causes
:::

::: {.column width="60%"}
::: fragment
**Violation of the independence assumption:** ![](img/w10/iv-independence-violation.png)
:::
:::
:::

## IV regression algorithm using 2SLS (1)

**Stage 1:** regress endogenous variable $s_i$ on all $X_i$ plus the instrument $Z_i$

$$
s_i = \pi_0 + \pi_1 Z_i + \rho X_i + \nu_i
$$

. . .

Compute fitted values form the stage 1: $\hat s_i = \pi_0 + \pi_1 Z_i + \rho X_i$.

. . .

Substitute $s_i$ with the $\hat{s_i}$ from the stage 1.

. . .

**Stage 2:** $Y_i = \alpha^{IV} + \rho^{IV} \hat{s_i} + \beta^{IV} X_i + \varepsilon^{IV}_i$

. . .

where

-   $\hat{s_i}$ are the fitted values from the first stage

-   $\rho^{IV}$ is the causal effect of interest from stage two that is asymptotically equal to $\rho$ , the true effect of interest ($\rho^{IV} \asymp \rho$)

# Wage and Education (again)

## Wage and Education (again)

$$
Y_i = \alpha^S + \rho^S s_i + \beta^S X_i + \varepsilon_i^S
$$

-   We know that estimate of years of education $s_i$ is biased because of the OVB (ability bias).

-   **Think of an RCT experiment that could help to estimate true causal effect of** $s_i$ on income!

-   What instrument $Z_i$ can we use for education?

## Fantastic IVs and how to find them...

1.  Use theory!

    -   human capital theory suggests that people make schooling choices by comparing the costs and benefits of alternatives.

2.  Think and speculate:

    -   What is the ideal experiment that could capture the effect of schooling on education?

    -   What are the forces you'd like to manipulate and the factors you'd like to hold constant?

    -   What are the other processes that are independent of wage, but may affect schooling?

3.  Analyze, what were/are the policies/environments that could mimic the experimental setting?

::: fragment
::: {.callout-important appearance="minimal"}
Reasoning on how researcher use theory and available observational data to approximate real experiment is called **Identification strategy**!
:::
:::

## Fantastic IVs for education

-   Loan policies or other subsidies that vary independently of ability or earnings potential

-   Region and time variation in school construction [@Duflo2001]

-   Proximity to college[@Card1994]

-   Quarter of birth [@Angrist1991a]

-   Parents education [@Buckles2013]

-   Number of siblings

## Using parents education as the IV for education {.smmaller}

```{r eval=FALSE, echo=TRUE}
library(tidyverse)
library(haven)
library(modelsummary)
dta <-
  read_csv("education_parents.csv") %>% 
  mutate(lwagehour = log(wage/hours)) %>% 
  mutate(parents_edu = feduc + meduc)
glimpse(dta)
```

```{r}
library(tidyverse)
library(haven)
library(modelsummary)
dta <-
  read_csv(here::here("exercises","ex10-IV", "education_parents.csv")) %>% 
  mutate(lwagehour = log(wage/hours)) %>% 
  mutate(parents_edu = feduc + meduc) %>% 
  filter(!is.na(parents_edu))
glimpse(dta)
```

## Estimating IV manually {.smaller}

```{r echo=TRUE}
# No IV
ols <-  lm(log(wage) ~ educ + exper + I(exper^2), data = dta)

# No IV but with controls for IQ
ols_iq <-  lm(log(wage) ~ educ + exper + I(exper^2) + IQ, data = dta)

# First stage
first_stage <- lm(educ ~ parents_edu + exper + I(exper^2), data = dta)

# Fitted values of endogenous regressor
dta_fitted <- dta %>% mutate(educ_fit = fitted(first_stage))

# Second stage
second_stage <- lm(log(wage) ~ educ_fit + exper + I(exper^2), data = dta_fitted)
```

```{r}
modelsummary(
  list(`OLS` = ols, `OLS (with ability proxi)` = ols_iq,
       `1 stage (par. educ.)` = first_stage, 
       `2 stage (par. educ.)` = second_stage),
  fmt = "%.3f",
  estimate = "{estimate}{stars} ({std.error})",
  statistic = NULL,
  coef_map = c(
    "educ" = "Education", 
    "educ_fit" = "Education", 
    "parents_edu" = "Parents educ.",
    "exper" = "Experience",  
    "I(exper^2)" = "Experience sq.",  
    "IQ" = "Ability proxi"
  ),
  gof_omit = "AIC|BIC|RMSE"
)
```

## Using siblings number as the IV for education {.smaller}

```{r echo=TRUE}
library(ivreg)
iv_fit2 <- ivreg(
  log(wage) ~ educ + exper + I(exper ^ 2) | sibs + exper + I(exper ^ 2) ,
  data = dta )
```

```{r}
modelsummary(
  list(`OLS` = ols, `OLS (with ability proxi)` = ols_iq,
       `1 stage (par. educ.)` = first_stage, 
       `2 stage (par. educ.)` = second_stage,
       `2 stage (siblings)` = iv_fit2),
  fmt = "%.3f",
  estimate = "{estimate}{stars} ({std.error})",
  statistic = NULL,
  coef_map = c(
    "educ" = "Education", 
    "educ_fit" = "Education", 
    "parents_edu" = "Parents educ.",
    "exper" = "Experience",  
    "I(exper^2)" = "Experience sq.",  
    "IQ" = "Ability proxi"
  ),
  gof_omit = "AIC|BIC|RMSE"
)
```

# Pitfalls of the IV

## Consistency and unbiasedness

-   IV estimates **are not unbiased**, but they **are consistent** [@Angrist2001].

    -   **Unbiasedness** means the estimator has a sampling distribution centered on the parameter of interest in a sample of any size, while

    -   **Consistency** only means that the estimator converges to the population parameter as the sample size grows.

. . .

::: callout-note
Researchers that use IV should aspire to work with **large samples**.
:::

-   No statistical tests is available for checking consistency

## Bad instruments (1)

1.  $Z_i$ that does not satisfy any of the Relevance condition, Exclusion restriction and Independence assumption;

## Bad instruments (2)

2.  $Z_i$ that correlate with omitted variable (OV) but **do not cause** changes in it or inflict simultaneity:

-   They result into much greater upwards shifting bias compare to the OLS;

-   For example the weather in Brazil and supply price and demand quantity of coffee:

    -   weather shifts the supply curve, it is random, thus it seems as a plausible instrument for price in the demand model

    -   the weather in Brazil determines supply expectations on futures exchange, thus, it also shifts the demand for coffee before the supply price is affected;

## Bad instruments (3)

3.  Weak instrument $Z_i$:

    -   When the instrument $Z_i$ is only weakly correlates with endogenous regressor $s_i$;

    -   Find a better one!

## Weak instrument test:

-   Run the first stage regression with and without the IV;

-   Compare the F-statistics

    -   If F-statistics with instrument is greater than that without **by 5 of more**,
    -   this is a sign of a strong instrument [@Staiger1997];

-   This test does not ensure that our instruments are independent of omitted variable $A^{'}_i$ or $Y_i$;

-   [see @angrist2001, @Staiger1997]

## Overidentification (1)

-   number of instruments $G$ exceeds the number of endogenous variables $K$.

    -   when the IV is overidentified, estimates are biased;
    -   bias is proportional to $K - G$;
    -   using fewer instruments therefore reduces bias;

-   If you have few candidates for IV and one endogenous regressor:

    -   select one IV for the first stage, and
    -   put the remaining instruments as controls into the second stage

## Overidentification (2)

Sargan's overidentification test:

-   $H_0:Cov(Z^{'}_i,\varepsilon^{IV}_i)=0$ - the covariance between the instrument and the error term is zero

-   $H_1:Cov(Z^{'}_i,\varepsilon^{IV}_i)\neq0$

-   Thus, by rejecting the $H_0$, we conclude that at least one of the instruments is not valid.

## Wu-Hausman test for endogeneity

Wu-Hausman test for endogeneity tests if the variable that we are worried about is indeed endogenous.

-   $H_0:Cov(s_i,\varepsilon_i)=0$ - the covariance between potentially endogenous variable and the error term is zero

-   $H_1:Cov(s_i,\varepsilon_i) \neq 0$

-   Thus, by rejecting the $H_0$, we conclude that there is endogeneity and there might be a need for IV.

# Example 1. The colonial origins of comparative development: An empirical investigation

[@Acemoglu2001]. The colonial origins of comparative development: An empirical investigation. American economic review, 91(5), 1369-1401.

## Research question and the problem

-   **What are the fundamental causes of the large differences in income per capita across countries?**

-   with better "institutions," more secure property rights, and less distortionary policies,

    -   countries invest more in physical and human capital, and
    -   use these factors more efficiently to
    -   achieve a greater level of income.

-   Institutions are a likely cause of income growth.

## Endogeneity problem

What could be the ideal experiment to find the effect of institutions on income?

-   Rich economies choose or can afford better institutions.

-   Economies that are different for a variety of reasons

    -   will differ both in their institutions and in their income per capita.

-   To estimate the impact of institutions on income,

    -   we need a **source of exogenous variation in institutions**.

## Identification strategy

is the manner in which a researcher uses observational data (i.e., data not generated by a randomized trial) to approximate a real experiment [@Angrist1991a]

. . .

::: columns
::: {.column width="50%"}
1.  Current performance is caused by

2.  Current **institutions**, which are caused by

3.  **Early institutions**, which are caused by

4.  **Settlements types** during colonization, which are caused by

5.  Settlers' (potential) **mortality or colonization risks**.
:::

::: {.column width="50%"}
::: fragment
![](img/w10/institution-identification.png)
:::
:::
:::

## Empirical model (OLS estimator)

$$
\begin{aligned}
\log (\text{GDP per capita}_i) & = \beta_0  \\ 
& + \beta_1 \text{Proxy for institutions} \\
& + \gamma \text{Control variables} + \epsilon_i
\end{aligned}
$$

-   $i$ is the country;

-   Dependent variable is the GDP per capita in 1995;

-   As the proxy of the institutional quality, authors used **average protection against expropriation risk in 1985-1990** (index/country ranking);

-   Controls include latitude of the country and continent-specific dummy variables;

## OLS estimation

![](img/w10/institution-ols.png)

## Empirical model (IV estimator)

First stage:

. . .

$$
\begin{aligned}
\text{Proxy for institutions}  & = \beta_0  \\ 
& + \beta_1 \log (\text{Settlers mortality in 16-18th cent.}) \\
& + \gamma \text{Control variables} + e_i,
\end{aligned}
$$

-   European settlers mortality in the 16-18th centuries is the precise number of how many settlers died in the country that they tried to colonize.

. . .

Second stage:

. . .

$$
\begin{aligned}
\log (\text{GDP per capita}_i) & = \beta_0^{IV}  \\ 
& + \beta_1^{IV} \widehat{ \text{Proxy for institutions}} \\
& + \gamma^{IV} \text{Control variables} + \epsilon_i^{IV},
\end{aligned}
$$

-   $\widehat{ \{ \text{Proxy for institutions} \}}$ are fitted values from the first stage.

## IV results

![](img/w10/institution-iv-2.png)

## References
